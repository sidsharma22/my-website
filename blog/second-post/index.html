<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.1.0">
<title data-rh="true">Why scaling helps the cost  function to converge faster? | Sidharth Sharma</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://sidsharma22.github.io/my-website/blog/second-post"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Why scaling helps the cost  function to converge faster? | Sidharth Sharma"><meta data-rh="true" name="description" content="TL;DR: Scaling the input features, causes the gradient of the cost to converge faster."><meta data-rh="true" property="og:description" content="TL;DR: Scaling the input features, causes the gradient of the cost to converge faster."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2022-11-08T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/sidsharma22/&quot;"><meta data-rh="true" property="article:tag" content="Gradient Descent,Cost Function,ML"><link data-rh="true" rel="icon" href="/my-website/img/sid.ico"><link data-rh="true" rel="canonical" href="https://sidsharma22.github.io/my-website/blog/second-post"><link data-rh="true" rel="alternate" href="https://sidsharma22.github.io/my-website/blog/second-post" hreflang="en"><link data-rh="true" rel="alternate" href="https://sidsharma22.github.io/my-website/blog/second-post" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/my-website/blog/rss.xml" title="Sidharth Sharma RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/my-website/blog/atom.xml" title="Sidharth Sharma Atom Feed">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/my-website/assets/css/styles.bc04ba9a.css">
<link rel="preload" href="/my-website/assets/js/runtime~main.052ec1e8.js" as="script">
<link rel="preload" href="/my-website/assets/js/main.8e28cfef.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<div role="region" aria-label="theme.common.skipToMainContent"><a href="#" class="skipToContent_fXgn">Skip to main content</a></div><nav class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/my-website/"><b class="navbar__title text--truncate">Sidharth Sharma</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/my-website/blog">thoughts</a><a class="navbar__item navbar__link" href="/my-website/projects">projects</a><a class="navbar__item navbar__link" href="/my-website/experience">experience</a><a href="https://github.com/sidsharma22" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link" alt="My Site Logo" src="img/logo.svg">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/my-website/blog/second-post">Why scaling helps the cost  function to converge faster?</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="title_f1Hy" itemprop="headline">Why scaling helps the cost  function to converge faster?</h1><div class="container_mt6G margin-vert--md"><time datetime="2022-11-08T00:00:00.000Z" itemprop="datePublished">November 8, 2022</time> · <!-- -->3 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/sidsharma22/&quot;" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://avatars.githubusercontent.com/u/37993073?s=400&amp;u=9c80d5d567d2d57fe699a018b48a15221640ff4e&amp;v=4" alt="Sidharth Sharma"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/sidsharma22/&quot;" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Sidharth Sharma</span></a></div><small class="avatar__subtitle" itemprop="description">Student @ Carnegie Mellon University</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><p>TL;DR: Scaling the input features, causes the gradient of the cost to converge faster.</p><p><img loading="lazy" alt="img alt" src="/my-website/assets/images/GD-1-68a3d4ec5a1098f5b9e3929d2bde566e.png" width="275" height="268" class="img_ev3q"></p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="introduction">Introduction<a class="hash-link" href="#introduction" title="Direct link to heading">​</a></h3><p>While running a machine learning experiment using linear regression, I noticed that the batch gradient descent algorithm converges faster when the data is scaled. Since, we know the effects of scaling helps in models like KNN where the magnitude of each observation plays a very important role, but why is convergence affected  in case of batch-gradient descent? Why was scaling having such a big impact?
In the experiment if I do not scale the features the algorithm does not converge in a fixed number of steps. After scaling, the algorithm converges in half the number of steps initially used!
First, let’s look at the cost function that is in this experiment.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="cost-function">Cost function<a class="hash-link" href="#cost-function" title="Direct link to heading">​</a></h3><p>I used residual sum of squares error as the cost function in this experiment.
Rss = ((theta_0 + theta_1*x) - y )^2
This will give us an ellipse equation. But if we scale our input value (x) such that the values are between 0 and 1.  The equation smooths to look like a circle, when the equation is plotted with theta_0 on the x-axis and theta_1 on the y_axis. Moving forward, remember how scaling the input smooths the contour. </p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="how-do-gradients-work">How do gradients work?<a class="hash-link" href="#how-do-gradients-work" title="Direct link to heading">​</a></h3><p>The gradient of a multivariate  function gives us the direction where the function increases the fastest and its magnitude gives us the rate of increase. For a more intuitive example, think of burning an incense stick and then observing its smoke. In three dimensional space the smoke will move in one direction(xmax, ymax, zmax) faster as compared to other directions, and that is the gradient!</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="use-of-gradients-in-machine-learning">Use of Gradients in Machine Learning<a class="hash-link" href="#use-of-gradients-in-machine-learning" title="Direct link to heading">​</a></h3><p>All the parametric models in machine learning have a cost function. We try to find the minima of that cost function as we want our model to learn the relationship between our input data and the output label. With the help of gradients  we know how to calculate the direction of fastest increase in function. We use this technique to get the direction in which the cost of our system increases the most and then move in the opposite direction. Why the opposite? Because we want to reach the minimum point of this increasing function. Why the minimum? The minimum point will give us the minimum cost! </p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="gradient-of-an-ellipse-vs-circle">Gradient of an ellipse vs circle<a class="hash-link" href="#gradient-of-an-ellipse-vs-circle" title="Direct link to heading">​</a></h3><p><img loading="lazy" alt="img alt" src="/my-website/assets/images/GD-2-e1be80e564ba129a81f75659ef6089d9.png" width="627" height="244" class="img_ev3q">
One of the things we should remember in order to understand why scaling is required is that the gradient of an ellipse does not point to its center, whereas in the case of a circle the gradient will always point to the center. At the center lies the point where the cost is minimum.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="impact-of-scaling">Impact of scaling<a class="hash-link" href="#impact-of-scaling" title="Direct link to heading">​</a></h3><p>When we scale the inputs and squash the values between 0 - 1. This automatically smoothes the contours of our cost function to be more circular. Normalizing will result in a cost function with less elliptical and more &#x27;circular&#x27; contours. This gives us two advantages, the gradient would converge faster as its natural direction would be towards the center and we could increase the step size or learning rate “alpha” in this case to reach the minima even quicker, as there would be less zig-zag movement by the gradient vector to find the minima.</p></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/my-website/blog/tags/gradient-descent">Gradient Descent</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/my-website/blog/tags/cost-function">Cost Function</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/my-website/blog/tags/ml">ML</a></li></ul></div></footer></article></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#cost-function" class="table-of-contents__link toc-highlight">Cost function</a></li><li><a href="#how-do-gradients-work" class="table-of-contents__link toc-highlight">How do gradients work?</a></li><li><a href="#use-of-gradients-in-machine-learning" class="table-of-contents__link toc-highlight">Use of Gradients in Machine Learning</a></li><li><a href="#gradient-of-an-ellipse-vs-circle" class="table-of-contents__link toc-highlight">Gradient of an ellipse vs circle</a></li><li><a href="#impact-of-scaling" class="table-of-contents__link toc-highlight">Impact of scaling</a></li></ul></div></div></div></div></div></div>
<script src="/my-website/assets/js/runtime~main.052ec1e8.js"></script>
<script src="/my-website/assets/js/main.8e28cfef.js"></script>
</body>
</html>